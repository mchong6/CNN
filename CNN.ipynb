{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn';\n",
    "require 'paths'\n",
    "local matio = require 'matio'\n",
    "local tensor = matio.load('CIFAR2_reshaped.mat')\n",
    "test_X = tensor.test_X\n",
    "\n",
    "nRepeat = 4\n",
    "labelLength = nRepeat * 2\n",
    "numberTR0 = 5000\n",
    "numberTR1 = 5000\n",
    "numberTe0 = 500\n",
    "numberTe1 = 500\n",
    "label0 = torch.cat(torch.ones(nRepeat), torch.zeros(nRepeat),1)\n",
    "label1 = torch.cat(torch.zeros(nRepeat), torch.ones(nRepeat),1)\n",
    "\n",
    "train_Y = torch.cat(torch.repeatTensor(label0, numberTR0, 1), torch.repeatTensor(label1, numberTR1, 1), 1)\n",
    "test_Y = torch.cat(torch.repeatTensor(label0, numberTe0, 1), torch.repeatTensor(label1, numberTe1, 1), 1)\n",
    "\n",
    "tensors = {}\n",
    "tensors.data = tensor.train_X\n",
    "tensors.label = train_Y\n",
    "\n",
    "--print(label0)\n",
    "--print(train_Y[5001])\n",
    "--print(torch.type(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- ignore setmetatable for now, it is a feature beyond the scope of this tutorial. It sets the index operator.\n",
    "setmetatable(tensors, \n",
    "    {__index = function(t, i) \n",
    "                    return {t.data[i], t.label[i]} \n",
    "                end}\n",
    ");\n",
    "tensors.data = tensors.data:double() -- convert the data from a ByteTensor to a DoubleTensor.\n",
    "\n",
    "function tensors:size() \n",
    "    return self.data:size(1) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Channel 1, Mean: 122.45534121094\t"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 1, Standard Deviation: 63.385616790565\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 2, Mean: 120.61582177734\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 2, Standard Deviation: 62.504468929637\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 3, Mean: 111.08353691406\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 3, Standard Deviation: 66.274687121541\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = {} -- store the mean, to normalize the test set in the future\n",
    "stdv  = {} -- store the standard-deviation for the future\n",
    "for i=1,3 do -- over each image channel\n",
    "    mean[i] = tensors.data[{ {}, {i}, {}, {}  }]:mean() -- mean estimation\n",
    "    print('Channel ' .. i .. ', Mean: ' .. mean[i])\n",
    "    tensors.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction, :add(value) add value to all elements in place.\n",
    "    \n",
    "    stdv[i] = tensors.data[{ {}, {i}, {}, {}  }]:std() -- std estimation\n",
    "    print('Channel ' .. i .. ', Standard Deviation: ' .. stdv[i])\n",
    "    tensors.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling :div(value) divides all elements by value in place.\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialZeroPadding(2,2,2,2))\n",
    "net:add(nn.SpatialConvolution(3, 32, 5, 5)) -- 3 input image channels, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.Dropout(0.4))\n",
    "net:add(nn.ReLU())                       -- non-linearity, think of this as sigmoid function \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))     -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialZeroPadding(2,2,2,2))\n",
    "net:add(nn.SpatialConvolution(32, 32, 5, 5)) --repeat convolution\n",
    "net:add(nn.Dropout(0.4))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.SpatialZeroPadding(2,2,2,2))\n",
    "net:add(nn.SpatialConvolution(32, 64, 5, 5)) --repeat convolution\n",
    "net:add(nn.Dropout(0.4))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(64*4*4))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "net:add(nn.Linear(64*4*4, 120))             -- fully connected layer (matrix multiplication between input and weights), neural network, full connection.\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Dropout(0.5))\n",
    "net:add(nn.Linear(84, labelLength))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "net:add(nn.Sigmoid()) \n",
    "--net:add(nn.LogSoftMax())                     -- converts the output to a log-probability. Useful for classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSECriterion()\n",
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = 0.001\n",
    "trainer.maxIteration = 5 -- just do 5 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer:train(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_X = test_X:double()   -- convert from Byte tensor to Double tensor\n",
    "for i=1,3 do -- over each image channel\n",
    "    tensors.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction    \n",
    "    tensors.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i=1,numberTe0 do\n",
    "    local prediction = net:forward(test_X[i])\n",
    "    if (prediction - label0)*(prediction - label0)< (prediction - label1) * (prediction -label1) then\n",
    "        correct = correct + 1\n",
    "    end\n",
    "end\n",
    "\n",
    "for i=numberTe0+1,numberTe0 + numberTe1 do\n",
    "    local prediction = net:forward(test_X[i])\n",
    "    if (prediction - label1)*(prediction - label1) < (prediction - label0)*(prediction - label0) then\n",
    "        correct = correct + 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(correct, 100*correct/(numberTe0+numberTe1) .. ' % ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
